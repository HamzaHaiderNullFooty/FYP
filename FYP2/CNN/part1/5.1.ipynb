{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "victorian-lindsay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-fb534204403d>:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  from tqdm._tqdm_notebook import tqdm_notebook\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import gensim.downloader as api\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "import inspect\n",
    "import re as re\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vertical-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 45000\n",
    "embedding_dim = 512\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biblical-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('classifier_data_0.csv', header = 0, encoding= 'utf-8')\n",
    "dataset.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4','Unnamed: 5','Unnamed: 6','Unnamed: 7','Unnamed: 8','Unnamed: 9', 'Unnamed: 10'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "innovative-sudan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            description  \\\n",
      "4576  product version       see aboutversionurls if ...   \n",
      "3457  Version: 32.0.1653.0 (Official Build 225591) c...   \n",
      "3879  When I try to add my self to review a code in ...   \n",
      "788   Currently enter_chroot.sh has a hack to preser...   \n",
      "307   Product Version      : <see about:version>URLs...   \n",
      "\n",
      "                        owner  \n",
      "4576                    <OOV>  \n",
      "3457      kinaba@chromium.org  \n",
      "3879    nsylvain@chromium.org  \n",
      "788   davidjames@chromium.org  \n",
      "307          jon@chromium.org  \n"
     ]
    }
   ],
   "source": [
    "X= dataset['description']\n",
    "y = dataset['owner']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1500)\n",
    "X_train.shape\n",
    "df = pd.DataFrame(data=[X_train, y_train], index=[\"description\", \"owner\"]).T\n",
    "df = df.append(pd.DataFrame(data=[X_test, y_test], index=[\"description\", \"owner\"]).T)\n",
    "\n",
    "\n",
    "df = df.replace({np.nan: oov_tok})\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handy-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['char_count'] = df['description'].apply(len) # Number of characters in the string\n",
    "df['word_count'] = df['description'].apply(lambda x: len(x.split())) # Number of words in the string \n",
    "df['word_density'] = df['char_count'] / (df['word_count']+1) # Density of word (in char)\n",
    "df['title_word_count'] = df['description'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "\n",
    "labels = df['owner'].unique()\n",
    "\n",
    "def remove(list):\n",
    "    pattern='[0-9]'\n",
    "    list = [re.sub(pattern, '',i) for i in list]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "committed-textbook",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_x, valid_x, y_train, y_valid = train_test_split(df['description'], df['owner'], random_state=42, test_size=0.2)\n",
    "\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(df['description'])\n",
    "word_index = token.word_index\n",
    "\n",
    "df['description']= remove(df['description'])\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=300)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=300)\n",
    "\n",
    "\n",
    "train_y = encoder.fit_transform(y_train)\n",
    "valid_y = encoder.fit_transform(y_valid)\n",
    "\n",
    " \n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=3)\n",
    "def create_conv_model(word_index, label, embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a convulational neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) convulational neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) +1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Conv1D(100, 5, activation='relu'), # padding='same'\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.Conv1D(32, 5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_conv_model(word_index, labels, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arranged-robert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 5.7339 - accuracy: 0.2044 - val_loss: 6.0330 - val_accuracy: 0.1912\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 5.5185 - accuracy: 0.2044 - val_loss: 5.9633 - val_accuracy: 0.1912\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 5.3771 - accuracy: 0.2044 - val_loss: 5.8498 - val_accuracy: 0.1912\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 5.1782 - accuracy: 0.2044 - val_loss: 5.6050 - val_accuracy: 0.1912\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 5.0560 - accuracy: 0.2044 - val_loss: 5.5527 - val_accuracy: 0.1912\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 4.9964 - accuracy: 0.2044 - val_loss: 5.4976 - val_accuracy: 0.1912\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.9481 - accuracy: 0.2044 - val_loss: 5.4222 - val_accuracy: 0.1912\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 4.9048 - accuracy: 0.2044 - val_loss: 5.3863 - val_accuracy: 0.1912\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 4.8690 - accuracy: 0.2044 - val_loss: 5.3223 - val_accuracy: 0.1912\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 4.8400 - accuracy: 0.2044 - val_loss: 5.2841 - val_accuracy: 0.1912\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 4.8126 - accuracy: 0.2044 - val_loss: 5.2704 - val_accuracy: 0.1912\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 4.7903 - accuracy: 0.2044 - val_loss: 5.2437 - val_accuracy: 0.1912\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 4.7650 - accuracy: 0.2041 - val_loss: 5.2288 - val_accuracy: 0.1900\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 4.7431 - accuracy: 0.2028 - val_loss: 5.2234 - val_accuracy: 0.1900\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 4.7186 - accuracy: 0.2034 - val_loss: 5.2202 - val_accuracy: 0.1887\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 4.6971 - accuracy: 0.2069 - val_loss: 5.2114 - val_accuracy: 0.1950\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 4.6755 - accuracy: 0.2125 - val_loss: 5.2086 - val_accuracy: 0.2025\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 4.6508 - accuracy: 0.2172 - val_loss: 5.2081 - val_accuracy: 0.2075\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 4.6317 - accuracy: 0.2212 - val_loss: 5.2071 - val_accuracy: 0.2113\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 4.6053 - accuracy: 0.2234 - val_loss: 5.2117 - val_accuracy: 0.2163\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_seq_x, train_y, epochs=20, callbacks=[es], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-cover",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opening-perfume",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 31ms/step - loss: 6.6540 - accuracy: 0.0040\n",
      "[6.654043197631836, 0.004000000189989805]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(valid_seq_x, valid_y)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-setup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-impact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-sustainability",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-saturday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-polls",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-helmet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-investigation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-personal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv] *",
   "language": "python",
   "name": "conda-env-.conda-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
