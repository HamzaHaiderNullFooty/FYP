{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import os\n",
    "\n",
    "training = pd.read_csv('classifier_data_10.csv', header = 0)\n",
    "testing = pd.read_csv('deep_data.csv', header = 0, delimiter = \",\")\n",
    "testing.drop(['Unnamed: 2'], axis=1, inplace = True)\n",
    "training.drop(['Unnamed: 3','Unnamed: 4'], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "training['description'] = training['description'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "# Removing punctuation\n",
    "training['description'] = training['description'].str.replace('[^\\w\\s]','')\n",
    "# Stop word removal\n",
    "stop = stopwords.words('english')\n",
    "training['description'] = training['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "#Stemming\n",
    "st = PorterStemmer()\n",
    "training['description'] = training['description'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "\n",
    "\n",
    "training['description'].head()\n",
    "\n",
    "X=training[['description']]  # Features\n",
    "y=training[['owner']]\n",
    "\n",
    "X_test = testing[['description']]  # Features\n",
    "\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 200) \n",
    "                             \n",
    "vectorizer.fit(X['description'])\n",
    "vector = vectorizer.transform(X['description'])\n",
    "train_data_features=vector.toarray()\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 150) \n",
    "forest = forest.fit( train_data_features, y['owner'])\n",
    "\n",
    "vectorizer1 = TfidfVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 200) \n",
    "                             \n",
    "vector1 = vectorizer1.fit_transform(X_test['description'].apply(lambda x: np.str_(x)))\n",
    "\n",
    "test_data_features=vector1.toarray()\n",
    "\n",
    "result = forest.predict(test_data_features)\n",
    "output = pd.DataFrame( data={\"id\":testing[\"id\"], \"owner\":result, \"description\":testing[\"description\"]} )\n",
    "\n",
    "output.to_csv('dataset3_TFIDF_result.csv', index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
